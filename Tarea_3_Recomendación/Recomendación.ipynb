{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recomendación. Campaña de email marketing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objetivo\n",
    "\n",
    "- Desarrollar una estrategia de email marketing dirigida a 10,000 clientes, priorizando los productos que generen mayor beneficio.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aspectos a tener en cuenta\n",
    "\n",
    "1. Modelos de Predicción:\n",
    "\n",
    "- Crear modelos predictivos para determinar qué productos tienen mayor probabilidad de ser contratados por cada cliente.\n",
    "- Considerar no solo la probabilidad de contratación, sino también el beneficio económico de cada producto.\n",
    "- Utilizar técnicas de modelado avanzadas como árboles de decisión, regresión logística y redes neuronales.\n",
    "- Validar y evaluar los modelos utilizando métricas como la precisión, el recall y el AUC-ROC.\n",
    "2. Selección de Clientes:\n",
    "- Seleccionar los 10,000 clientes que recibirán los emails basados en los resultados del modelo predictivo.\n",
    "- Justificar la elección de estos clientes y la estrategia empleada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enfoques para la creación de los modelos predictivos\n",
    "\n",
    "1. Creación de un modelo para cada producto:\n",
    "\n",
    "- En este enfoque, se crearía un modelo predictivo separado para cada producto (por ejemplo, uno para short_term_deposit, otro para loans, otro para mortgage, etc.).\n",
    "\n",
    "- Ventajas: Es específico para cada producto. El modelo se entrenaría específicamente para un producto, lo que permite que aprenda patrones únicos relacionados con la contratación de ese producto.\n",
    "- Interpretabilidad: Los factores que influyen en la contratación de cada producto pueden ser más fáciles de interpretar.\n",
    "- Desventajas: Sería costoso en términos de recursos ya que requiere entrenar y mantener múltiples modelos. Además, muchos de los modelos podrían utilizar características similares, lo que significa que se estaría trabajando doble.\n",
    "\n",
    "2. Modelo agrupado por tipos de productos:\n",
    "\n",
    "- Se agruparían los productos similares en categorías, exactamente como lo explicaba Erin (Responsable de Marketing Directo) en uno de sus correos [cuentas, productos de ahorro e inversión (planes, fondos, etc.) y financiación (préstamos y tarjetas)].\n",
    "\n",
    "- Ventajas: Menos modelos que mantener en comparación con la opción de un modelo por producto. Además, se pueden identificar patrones que se aplican a categorías de productos.\n",
    "- Desventajas: Puede que no capture detalles específicos de un solo producto tan bien como un modelo dedicado.\n",
    "\n",
    "3. Modelo General para Todos los Productos:\n",
    "\n",
    "- Se utilizaría un único modelo para predecir la probabilidad de que un cliente contrate cualquier producto, saliendo con una lista de productos con probabilidades.\n",
    "- Ventajas: Es simple, solo hay que entrenar y mantener un único modelo, por tanto menos recursos computacionales y menos tiempo de entrenamiento.\n",
    "- Desventajas: Puede ser más complejo interpretar las relaciones ya que el modelo tiene que captar información de todos los productos y si un producto es raro comparado con otros, el modelo puede no predecirlo correctamente.\n",
    "\n",
    "Recomendación de Enfoque\n",
    "\n",
    "Basado en los productos y tu conjunto de datos, podrías optar por un enfoque híbrido:\n",
    "\n",
    "\t1.\tEmpezar con un Modelo General: Entrenar un modelo inicial que prediga la probabilidad de contratación de productos en general. Este modelo puede ayudarte a identificar qué características son las más importantes para la contratación de productos en general.\n",
    "\t2.\tRefinar con Modelos Específicos para Productos Clave: Identifica productos clave (por ejemplo, aquellos que son más rentables o tienen un interés estratégico particular). Entrena modelos específicos para estos productos, utilizando las características identificadas en el modelo general.\n",
    "\t3.\tAgrupación por Categorías: Para productos que son similares o están relacionados, considera agruparlos en categorías y entrenar modelos basados en estas categorías.\n",
    "\n",
    "Proceso para Entrenar los Modelos\n",
    "\n",
    "Independientemente del enfoque elegido, los siguientes pasos te ayudarán a entrenar y evaluar tus modelos:\n",
    "\n",
    "\t1.\tPreprocesamiento de Datos:\n",
    "\t•\tCodificación de Variables Categóricas: Usar técnicas como codificación one-hot o codificación de etiquetas para columnas categóricas como region_code, gender, entry_channel, etc.\n",
    "\t•\tEscalado de Características: Escalar características numéricas (como age, salary) para estandarizar el rango de valores.\n",
    "\t•\tManejo de Valores Faltantes: Decidir cómo tratar con valores faltantes (imputación, eliminación, etc.).\n",
    "\t2.\tDivisión del Conjunto de Datos:\n",
    "\t•\tDividir los datos en conjuntos de entrenamiento y prueba. Usualmente se usa una proporción de 80/20 o 70/30.\n",
    "\t•\tOpcional: Dividir en conjunto de entrenamiento, validación y prueba para ajuste de hiperparámetros.\n",
    "\t3.\tSelección de Modelos:\n",
    "\t•\tUtilizar algoritmos de clasificación como regresión logística, árboles de decisión, bosques aleatorios, XGBoost, o redes neuronales dependiendo de la complejidad del problema y los datos disponibles.\n",
    "\t4.\tEntrenamiento y Evaluación:\n",
    "\t•\tEntrenar el modelo usando el conjunto de entrenamiento.\n",
    "\t•\tEvaluar el modelo usando métricas como precisión, recall, F1-score, y ROC-AUC para clasificar los resultados.\n",
    "\t•\tAjustar hiperparámetros utilizando técnicas como grid search o random search.\n",
    "\t5.\tPredicción y Recomendación:\n",
    "\t•\tUtilizar los modelos para predecir las probabilidades de éxito de productos específicos para cada cliente.\n",
    "\t•\tPriorizar las recomendaciones basadas en las probabilidades predichas.\n",
    "\n",
    "Ejemplo de Implementación de un Modelo General en Python\n",
    "\n",
    "A continuación, se muestra un ejemplo básico utilizando un modelo de clasificación para predecir la probabilidad de contratación de un producto genérico:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cargando el dataset de productos desde S3 de AWS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/claudiacastro/anaconda3/lib/python3.11/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluación del modelo para credit_card:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00   1178265\n",
      "           1       0.78      0.75      0.77     14320\n",
      "\n",
      "    accuracy                           0.99   1192585\n",
      "   macro avg       0.89      0.87      0.88   1192585\n",
      "weighted avg       0.99      0.99      0.99   1192585\n",
      "\n",
      "ROC-AUC Score: 0.96\n",
      "Evaluación del modelo para loans:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00   1192490\n",
      "           1       0.93      0.84      0.88        95\n",
      "\n",
      "    accuracy                           1.00   1192585\n",
      "   macro avg       0.97      0.92      0.94   1192585\n",
      "weighted avg       1.00      1.00      1.00   1192585\n",
      "\n",
      "ROC-AUC Score: 0.97\n",
      "Evaluación del modelo para mortgage:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00   1192519\n",
      "           1       0.98      0.95      0.97        66\n",
      "\n",
      "    accuracy                           1.00   1192585\n",
      "   macro avg       0.99      0.98      0.98   1192585\n",
      "weighted avg       1.00      1.00      1.00   1192585\n",
      "\n",
      "ROC-AUC Score: 0.98\n",
      "Evaluación del modelo para short_term_deposit:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00   1189519\n",
      "           1       0.65      0.45      0.53      3066\n",
      "\n",
      "    accuracy                           1.00   1192585\n",
      "   macro avg       0.82      0.73      0.77   1192585\n",
      "weighted avg       1.00      1.00      1.00   1192585\n",
      "\n",
      "ROC-AUC Score: 0.95\n",
      "          pk_cid  beneficio_total_esperado\n",
      "968686   1051389               1050.000000\n",
      "1307509  1022142               1050.000000\n",
      "4523276  1016656               1050.000000\n",
      "5839564  1022142               1050.000000\n",
      "5521587   940553               1050.000000\n",
      "...          ...                       ...\n",
      "1224413   585639                 60.333333\n",
      "832159   1378416                 60.333333\n",
      "4646789  1439788                 60.333333\n",
      "727559    585639                 60.333333\n",
      "1374377  1389741                 60.333333\n",
      "\n",
      "[10000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score, classification_report\n",
    "\n",
    "\n",
    "ca_df = pd.read_parquet('https://easy-money-project-bucket.s3.eu-west-3.amazonaws.com/products_df.parquet')\n",
    "# Suponiendo que ca_df es tu DataFrame con los datos históricos\n",
    "# Lista de productos\n",
    "productos = ['credit_card', 'loans', 'mortgage', 'short_term_deposit']\n",
    "\n",
    "# Diccionario para almacenar modelos y beneficios\n",
    "modelos = {}\n",
    "beneficios_por_producto = {\n",
    "    'credit_card': 50,   # Beneficio estimado en dólares\n",
    "    'loans': 500,\n",
    "    'mortgage': 1000,\n",
    "    'short_term_deposit': 100\n",
    "}\n",
    "\n",
    "# Para cada producto, crear y entrenar un modelo\n",
    "for producto in productos:\n",
    "    # Crear una columna de target para cada producto\n",
    "    ca_df[f'target_{producto}'] = ca_df[producto]\n",
    "    \n",
    "    # Definir las características y la variable target\n",
    "    X = ca_df.drop([f'target_{producto}', producto, 'pk_partition', 'Unnamed: 0'], axis=1)\n",
    "    X.fillna(0, inplace=True)\n",
    "    y = ca_df[f'target_{producto}']\n",
    "    \n",
    "    # Convertir variables categóricas a numéricas\n",
    "    X = pd.get_dummies(X)\n",
    "    \n",
    "    # Dividir en conjunto de entrenamiento y prueba\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Entrenar un modelo, por ejemplo, un RandomForestClassifier\n",
    "    model = RandomForestClassifier(n_estimators=5, random_state=42, n_jobs=-1)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Guardar el modelo entrenado\n",
    "    modelos[producto] = model\n",
    "    \n",
    "    # Evaluar el modelo\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_prob = model.predict_proba(X_test)[:, 1]\n",
    "    print(f\"Evaluación del modelo para {producto}:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(f\"ROC-AUC Score: {roc_auc_score(y_test, y_pred_prob):.2f}\")\n",
    "    \n",
    "    # Calcular probabilidades de contratación para todos los clientes en el conjunto original\n",
    "    ca_df[f'probabilidad_{producto}'] = model.predict_proba(X)[:, 1]\n",
    "\n",
    "    # Calcular el beneficio esperado para cada producto y cliente\n",
    "    ca_df[f'beneficio_esperado_{producto}'] = ca_df[f'probabilidad_{producto}'] * beneficios_por_producto[producto]\n",
    "\n",
    "# Sumar el beneficio esperado para todos los productos\n",
    "ca_df['beneficio_total_esperado'] = ca_df[[f'beneficio_esperado_{producto}' for producto in productos]].sum(axis=1)\n",
    "\n",
    "# Seleccionar los 10,000 clientes con mayor beneficio total esperado\n",
    "top_10000_clientes = ca_df.sort_values('beneficio_total_esperado', ascending=False).head(10000)\n",
    "\n",
    "# Mostrar los 10,000 clientes seleccionados\n",
    "print(top_10000_clientes[['pk_cid', 'beneficio_total_esperado']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9025"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.95**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.125"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.5**3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.5**3*40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Comportamientos clientes que se repiten en las particiones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear la tabla de presencia\n",
    "presence_table = pd.crosstab(ca_df['pk_cid'], ca_df['pk_partition'])\n",
    "\n",
    "# Visualizar la tabla de presencia\n",
    "presence_table.reset_index(inplace=True)\n",
    "presence_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un mapa de calor de actividad de clientes\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(presence_table.drop('pk_cid', axis=1), cmap='YlGnBu', cbar=True)\n",
    "plt.xlabel('Mes')\n",
    "plt.ylabel('Cliente (pk_cid)')\n",
    "plt.title('Mapa de Calor de la Actividad de Clientes por Mes')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
